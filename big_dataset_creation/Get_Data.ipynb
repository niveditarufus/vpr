{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27ed83ec-5e61-4c83-9d2f-d5963c88bc58",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Stanford_Online_Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7348e315-dd81-4080-8ceb-0039e09b86d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cvgl.stanford.edu/projects/lifted_struct/ \n",
    "#Download and unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2505eb03-5be5-418c-a3d4-08cad24ffaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "import hub\n",
    "from glob import glob\n",
    "import cv2\n",
    "import albumentations as A\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b1597-ffbe-454c-abd0-2b5782d815d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = glob('Stanford_Online_Products/Stanford_Online_Products/*/')\n",
    "full_classes = list(map(lambda x: x.split('/')[-2], classes))\n",
    "all_imgs = []\n",
    "all_cls = []\n",
    "\n",
    "for i in trange(len(classes)):\n",
    "    img_files = glob(os.path.join(classes[i], '*'))\n",
    "    cl = full_classes.index(classes[i].split('/')[-2])\n",
    "#     \n",
    "    all_cls.extend([cl for _ in range(len(img_files))])\n",
    "    all_imgs.extend(img_files)\n",
    "df_dict = {'image_files': all_imgs,\n",
    "           'labels': all_cls}\n",
    "df = pd.DataFrame(df_dict)\n",
    "df.to_csv('Stanford_Online_Products/Stanford_Products_extracted.csv', index=False)\n",
    "print(df.nunique())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52a250-69b6-4e58-91a8-1ecc326bc14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df.groupby('labels').count()\n",
    "(count>10).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a7b966-17f3-4988-8211-4e1422d596a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Fashion_200K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d16dbb1-4370-4697-ace5-751c8dec58a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/mayukh18/fashion200k-dataset\n",
    "# !mkdir Fashion_200K\n",
    "# !kaggle datasets download -d mayukh18/fashion200k-dataset -p Fashion_200K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ff9d9-5a8c-4e45-8405-05641302baca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !unzip -o -q Fashion_200K/fashion200k-dataset.zip -d Fashion_200K/\n",
    "# !rm -rf Fashion_200K/detection\n",
    "# !rm -rf /Fashion_200K/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b0a9b0-d030-45e5-ac6f-02e83e970086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import hub\n",
    "from glob import glob\n",
    "import cv2\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf2e331-764d-459b-b1cd-c4bce3c1256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = glob('Fashion_200K/women/*/*')\n",
    "all_imgs = []\n",
    "all_cls  = []\n",
    "\n",
    "for i in trange(len(classes)):\n",
    "    img_files = glob(os.path.join(classes[i], '*/*'))\n",
    "    try:\n",
    "        cl = full_classes.index(classes[i].split('/')[-1])\n",
    "    except:\n",
    "        pass\n",
    "    all_cls.extend([cl for _ in range(len(img_files))])\n",
    "    all_imgs.extend(img_files)\n",
    "df_dict = {'image_files': all_imgs,\n",
    "           'labels': all_cls}\n",
    "df = pd.DataFrame(df_dict)\n",
    "df.to_csv('Fashion_200K/Fashion_200K_extracted.csv', index=False)\n",
    "print(df.nunique())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bb6ad4-4e8c-4aa5-8bb1-c4a4753606e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df.groupby('labels').count()\n",
    "(count>10).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d49d5-15b4-4f60-871a-bb3ac6ba4a73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### DeepFashion （Consumer-to-shop）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1d95df-1070-4067-a42f-e4face3c9dc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/sangamman/deepfashion-consumer-to-shop-training\n",
    "# !mkdir deepFashion\n",
    "# !kaggle datasets download -d sangamman/deepfashion-consumer-to-shop-training -p deepFashion \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efca1afc-cc1b-488d-9293-e147830a0cbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!unzip -o -q deepFashion/deepfashion-consumer-to-shop-training.zip -d deepFashion/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a06d73-8bbc-4e7b-8062-23caf13a24f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "import hub\n",
    "from glob import glob\n",
    "import cv2\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186d31a-2c75-428b-bf73-3389221a5d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = glob('deepFashion/deepfashion/train/*/*')\n",
    "full_classes = list(map(lambda x: x.split('/')[-1].split('_')[1], classes))\n",
    "classes = glob('deepFashion/deepfashion/*/*/*')\n",
    "# print(classes, full_classes)\n",
    "\n",
    "all_imgs = []\n",
    "all_cls  = []\n",
    "for i in trange(len(classes)):\n",
    "    img_files = glob(os.path.join(classes[i], '*/*'))\n",
    "    try:\n",
    "        cl = full_classes.index(classes[i].split('/')[-1].split('_')[1])\n",
    "    except:\n",
    "        full_classes.append(classes[i].split('/')[-1].split('_')[1])\n",
    "        cl = full_classes.index(classes[i].split('/')[-1].split('_')[1])\n",
    "    all_cls.extend([cl for _ in range(len(img_files))])\n",
    "    all_imgs.extend(img_files)\n",
    "df_dict = {'image_files': all_imgs,\n",
    "           'labels': all_cls}\n",
    "df1 = pd.DataFrame(df_dict)\n",
    "print(df1.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69fc2be-89c6-4b4e-9ccb-3355034a68c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([df1, df2], axis=0).reset_index(drop=True)\n",
    "df1.to_csv('deepFashion/deepFashion_extracted.csv', index=False)\n",
    "print(df1.nunique())\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f5b52a-9817-4ecc-9fc5-5f5321ef140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df.groupby('labels').count()\n",
    "(count>10).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dbc7ea-7675-43d5-b4db-04e8b73c72db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Grocery Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622575e6-dad2-4735-9fc6-6c25a3cbeb26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git clone git@github.com:marcusklasson/GroceryStoreDataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a580dbb-9e9a-4886-9dc8-c072a24f432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "import hub\n",
    "from glob import glob\n",
    "import cv2\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c1799b-d107-4b39-a23f-326e47c2358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = glob('GroceryStoreDataset/dataset/train/*/*')\n",
    "full_classes = list(map(lambda x: x.split('/')[-1], classes))\n",
    "classes = glob('GroceryStoreDataset/dataset/*/*/*')\n",
    "\n",
    "all_imgs = []\n",
    "all_cls  = []\n",
    "for i in trange(len(classes)):\n",
    "    img_files = glob(os.path.join(classes[i], '*'))\n",
    "    # print(img_files)\n",
    "    try:\n",
    "        cl = full_classes.index(classes[i].split('/')[-1])\n",
    "        # print(classes[i])\n",
    "    except:\n",
    "        full_classes.append(classes[i].split('/')[-1])\n",
    "        cl = full_classes.index(classes[i].split('/')[-1])\n",
    "    all_cls.extend([cl for _ in range(len(img_files))])\n",
    "    all_imgs.extend(img_files)\n",
    "df_dict = {'image_files': all_imgs,\n",
    "           'labels': all_cls}\n",
    "df = pd.DataFrame(df_dict)\n",
    "df.to_csv('GroceryStoreDataset/grocery_dataset_extracted.csv', index=False)\n",
    "print(df.nunique())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776d5125-2bad-4f43-af9c-38c6be1cc70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df.groupby('labels').count()\n",
    "(count>3).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5166515-289c-4512-9477-2231048503ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### DeepFashion2（hard-triplets）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9bc844-82ae-4e22-9159-85727212af8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/sangamman/deepfashion2-hard-triplets\n",
    "# !mkdir deepFashion2\n",
    "# !kaggle datasets download -d sangamman/deepfashion2-hard-triplets -p deepFashion2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b23876-7048-4fc1-96d0-754dc46899ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !unzip -o -q deepFashion2/deepfashion2-hard-triplets.zip -d deepFashion2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2220f9fb-9087-4b4b-8a5c-17334e553bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c282c8d-84a2-4e4a-b845-2b3a63956840",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = glob('deepFashion2/fasion*/*/*')\n",
    "full_classes = glob('deepFashion2/fasion_dataset_similar_pair_croped_train/*')\n",
    "full_classes = list(map(lambda x: x.split('/')[-1], full_classes))\n",
    "# print(full_classes,classes)\n",
    "all_imgs = []\n",
    "all_cls  = []\n",
    "for i in trange(len(classes)):\n",
    "    img_files = glob(os.path.join(classes[i], '*/*'))\n",
    "    # print(classes[i].split('/')[-2])\n",
    "    try:\n",
    "        cl = full_classes.index(classes[i].split('/')[-2])\n",
    "    except:\n",
    "        pass\n",
    "    all_cls.extend([cl for _ in range(len(img_files))])\n",
    "    all_imgs.extend(img_files)\n",
    "\n",
    "df_dict = {'image_files': all_imgs,\n",
    "           'labels': all_cls}\n",
    "df = pd.DataFrame(df_dict)\n",
    "df.to_csv('deepFashion2/deepFashion2_extracted.csv', index=False)\n",
    "print(df.nunique())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bca3af-e909-4bc4-9750-7330c645766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df.groupby('labels').count()\n",
    "(count>3).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c824274a-4ab3-4585-a604-8b132e50e797",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### RP2K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2926ae65-d90e-46e2-bd8a-39909578fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.pinlandata.com/rp2k_dataset/\n",
    "# !mkdir rp2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aaf1b7-5b49-4573-a28e-80ce187d6464",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !wget https://blob-nips2020-rp2k-dataset.obs.cn-east-3.myhuaweicloud.com/rp2k_dataset.zip -P rp2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c83e5-2723-4093-a2a9-9feaa71631e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !unzip -o -q rp2k/rp2k_dataset.zip -d rp2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44f93cc-92e5-4b5a-97a7-0b045da504d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69975402-95fc-4941-ab55-ee426e722113",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_classes = glob('rp2k/all/train/*')\n",
    "full_classes = list(map(lambda x: x.split('/')[-1], full_classes))\n",
    "classes = glob('rp2k/*/*/*')\n",
    "# print(classes, full_classes)\n",
    "all_imgs = []\n",
    "all_cls  = []\n",
    "for i in trange(len(classes)):    \n",
    "    img_files = glob(os.path.join(classes[i], '*'))\n",
    "    try:\n",
    "        cl = full_classes.index(classes[i].split('/')[-1])\n",
    "    except:\n",
    "        full_classes.append(classes[i].split('/')[-1])\n",
    "        cl = full_classes.index(classes[i].split('/')[-1])\n",
    "    all_cls.extend([cl for _ in range(len(img_files))])\n",
    "    all_imgs.extend(img_files)\n",
    "df_dict = {'image_files': all_imgs,\n",
    "           'labels': all_cls}\n",
    "df = pd.DataFrame(df_dict)\n",
    "df.to_csv('rp2k/rp2k_extracted.csv', index=False)\n",
    "print(df.nunique())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e9bcce-b3b8-49fd-9023-4603598a2ed6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Shopee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d6c296-984e-419f-8c0d-5a42c9a61317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/competitions/shopee-product-matching\n",
    "# !mkdir Shopee\n",
    "# !kaggle competitions download -c shopee-product-matching -p Shopee\n",
    "# !unzip -o -q Shopee/shopee-product-matching.zip -d Shopee/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e2cda4-b88d-4e43-bca9-12e0497240e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### JD-product-10K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a0d482-7717-4773-b980-201e31be0247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/products-10k\n",
    "# !mkdir products10k\n",
    "# !kaggle competitions download -c products-10k -p products10k\n",
    "# # images need to be downloaded from one drive link provided in kaggle and unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c3e8f-57f8-4e12-ab44-e811c1385da0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !unzip -o -q products10k/products-10k.zip -d products10k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8869cdc-bed8-438a-86d1-329d89356557",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mkdir products10k/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e57135-7e2a-4ab6-8773-e6f69448563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -o -q products10k/train.zip -d products10k/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97be10a-adcd-46e6-95db-3d5fce5c8ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
