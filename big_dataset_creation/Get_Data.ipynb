{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4811f1f2",
   "metadata": {},
   "source": [
    "#### Stanford_Online_Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e16431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cvgl.stanford.edu/projects/lifted_struct/\n",
    "# !aria2c -x 3 \"ftp://cs.stanford.edu/cs/cvgl/Stanford_Online_Products.zip\" -d \"autodl-tmp/ori_data/\"\n",
    "# ! unzip -q autodl-tmp/ori_data/Stanford_Online_Products.zip -d autodl-tmp/ori_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "178320db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "130d3276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120053/120053 [00:20<00:00, 5924.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_files    120053\n",
      "labels          22634\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_files</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autodl-tmp/ori_data/Stanford_Online_Products/c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>autodl-tmp/ori_data/Stanford_Online_Products/c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>autodl-tmp/ori_data/Stanford_Online_Products/c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>autodl-tmp/ori_data/Stanford_Online_Products/c...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>autodl-tmp/ori_data/Stanford_Online_Products/c...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         image_files  labels\n",
       "0  autodl-tmp/ori_data/Stanford_Online_Products/c...       0\n",
       "1  autodl-tmp/ori_data/Stanford_Online_Products/c...       1\n",
       "2  autodl-tmp/ori_data/Stanford_Online_Products/c...       2\n",
       "3  autodl-tmp/ori_data/Stanford_Online_Products/c...       3\n",
       "4  autodl-tmp/ori_data/Stanford_Online_Products/c...       4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_imgs = glob('autodl-tmp/ori_data/Stanford_Online_Products/*/*')\n",
    "classes = []\n",
    "all_cls = []\n",
    "for file in tqdm(all_imgs):\n",
    "    cl_idx = file.split('/')[-1].split('_')[0]\n",
    "    try:\n",
    "        cl = classes.index(cl_idx)\n",
    "    except:\n",
    "        classes.append(cl_idx)\n",
    "        cl = classes.index(cl_idx)\n",
    "    all_cls.append(cl)\n",
    "df_dict = {'image_files': all_imgs,\n",
    "           'labels': all_cls}\n",
    "df = pd.DataFrame(df_dict)\n",
    "df.to_csv('autodl-tmp/ori_data/Stanford_Online_Products/Stanford_Products.csv', index=False)\n",
    "print(df.nunique())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9dd458b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_files    2110\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = df.groupby('labels').count()\n",
    "(count>10).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a7eda8",
   "metadata": {},
   "source": [
    "#### Fashion_200K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3456a25d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/mayukh18/fashion200k-dataset\n",
    "\n",
    "# !kaggle datasets download -d mayukh18/fashion200k-dataset -p autodl-tmp/ori_data/Fashion_200K\n",
    "!unzip -q -o autodl-tmp/ori_data/Fashion_200K/fashion200k-dataset.zip -d autodl-tmp/ori_data/Fashion_200K/\n",
    "!rm -rf autodl-tmp/ori_data/Fashion_200K/detection\n",
    "!rm -rf autodl-tmp/ori_data/Fashion_200K/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed87d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "219edfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_files    338339\n",
      "labels         106000\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_files</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autodl-tmp/ori_data/Fashion_200K/women/dresses...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>autodl-tmp/ori_data/Fashion_200K/women/dresses...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>autodl-tmp/ori_data/Fashion_200K/women/dresses...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>autodl-tmp/ori_data/Fashion_200K/women/dresses...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>autodl-tmp/ori_data/Fashion_200K/women/dresses...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         image_files  labels\n",
       "0  autodl-tmp/ori_data/Fashion_200K/women/dresses...       0\n",
       "1  autodl-tmp/ori_data/Fashion_200K/women/dresses...       0\n",
       "2  autodl-tmp/ori_data/Fashion_200K/women/dresses...       1\n",
       "3  autodl-tmp/ori_data/Fashion_200K/women/dresses...       1\n",
       "4  autodl-tmp/ori_data/Fashion_200K/women/dresses...       2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = glob('autodl-tmp/ori_data/Fashion_200K/women/*/*/*')\n",
    "all_imgs = []\n",
    "all_cls  = []\n",
    "for i in range(len(classes)):\n",
    "    img_files = glob(os.path.join(classes[i], '*'))\n",
    "    all_cls.extend([i for _ in range(len(img_files))])\n",
    "    all_imgs.extend(img_files)\n",
    "df_dict = {'image_files': all_imgs,\n",
    "           'labels': all_cls}\n",
    "df = pd.DataFrame(df_dict)\n",
    "df.to_csv('autodl-tmp/ori_data/Fashion_200K/Fashion_200K.csv', index=False)\n",
    "print(df.nunique())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47bbdb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_files    45174\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = df.groupby('labels').count()\n",
    "(count>3).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1898a311",
   "metadata": {},
   "source": [
    "#### DeepFashion （Consumer-to-shop）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7494dd2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading deepfashion-consumer-to-shop-training.zip to autodl-tmp/ori_data/DeepFashion\n",
      "100%|█████████████████████████████████████▉| 12.7G/12.7G [08:58<00:00, 34.3MB/s]\n",
      "100%|██████████████████████████████████████| 12.7G/12.7G [08:58<00:00, 25.3MB/s]\n",
      "unzip:  cannot find or open autodl-tmp/ori_data/DeepFashion_CTS/deepfashion-consumer-to-shop-training.zip, autodl-tmp/ori_data/DeepFashion_CTS/deepfashion-consumer-to-shop-training.zip.zip or autodl-tmp/ori_data/DeepFashion_CTS/deepfashion-consumer-to-shop-training.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/sangamman/deepfashion-consumer-to-shop-training\n",
    "\n",
    "!kaggle datasets download -d sangamman/deepfashion-consumer-to-shop-training -p autodl-tmp/ori_data/DeepFashion --unzip\n",
    "!unzip -o autodl-tmp/ori_data/DeepFashion_CTS/deepfashion-consumer-to-shop-training.zip -d autodl-tmp/ori_data/DeepFashion_CTS/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77cd77ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94366aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23593/23593 [00:04<00:00, 5698.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_files    120960\n",
      "labels          16940\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "classes = glob('autodl-tmp/ori_data/DeepFashion/deepfashion/train/*/*/*')\n",
    "full_classes = list(map(lambda x: x.split('/')[-1].split('_')[1], classes))\n",
    "classes = glob('autodl-tmp/ori_data/DeepFashion/deepfashion/train/*/*/*')\n",
    "all_imgs = []\n",
    "all_cls  = []\n",
    "for i in trange(len(classes)):\n",
    "    img_files = glob(os.path.join(classes[i], '*'))\n",
    "    try:\n",
    "        cl = full_classes.index(classes[i].split('/')[-1].split('_')[1])\n",
    "    except:\n",
    "        full_classes.append(classes[i].split('/')[-1].split('_')[1])\n",
    "        cl = full_classes.index(classes[i].split('/')[-1].split('_')[1])\n",
    "    all_cls.extend([cl for _ in range(len(img_files))])\n",
    "    all_imgs.extend(img_files)\n",
    "df_dict = {'image_files': all_imgs,\n",
    "           'labels': all_cls}\n",
    "df1 = pd.DataFrame(df_dict)\n",
    "print(df1.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5843fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11724/11724 [00:01<00:00, 9673.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_files    58747\n",
      "labels          8471\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "classes = glob('autodl-tmp/ori_data/DeepFashion/test/*/*/*/*')\n",
    "all_imgs = []\n",
    "all_cls  = []\n",
    "classes\n",
    "for i in trange(len(classes)):\n",
    "    img_files = glob(os.path.join(classes[i], '*', '*'))\n",
    "    try:\n",
    "        cl = full_classes.index(int(classes[i].split('/')[-1].split('_')[1]))\n",
    "    except:\n",
    "        full_classes.append(int(classes[i].split('/')[-1].split('_')[1]))\n",
    "        cl = full_classes.index(int(classes[i].split('/')[-1].split('_')[1]))\n",
    "    all_cls.extend([cl for _ in range(len(img_files))])\n",
    "    all_imgs.extend(img_files)\n",
    "df_dict = {'image_files': all_imgs,\n",
    "           'labels': all_cls}\n",
    "df2 = pd.DataFrame(df_dict)\n",
    "print(df2.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "519011d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_files    179707\n",
      "labels          19212\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_files</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autodl-tmp/ori_data/DeepFashion/deepfashion/tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>autodl-tmp/ori_data/DeepFashion/deepfashion/tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>autodl-tmp/ori_data/DeepFashion/deepfashion/tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>autodl-tmp/ori_data/DeepFashion/deepfashion/tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>autodl-tmp/ori_data/DeepFashion/deepfashion/tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         image_files  labels\n",
       "0  autodl-tmp/ori_data/DeepFashion/deepfashion/tr...       0\n",
       "1  autodl-tmp/ori_data/DeepFashion/deepfashion/tr...       0\n",
       "2  autodl-tmp/ori_data/DeepFashion/deepfashion/tr...       0\n",
       "3  autodl-tmp/ori_data/DeepFashion/deepfashion/tr...       0\n",
       "4  autodl-tmp/ori_data/DeepFashion/deepfashion/tr...       0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df1, df2], axis=0).reset_index(drop=True)\n",
    "df.to_csv('autodl-tmp/ori_data/DeepFashion/DeepFashion.csv', index=False)\n",
    "print(df.nunique())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fd91590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_files    6165\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = df.groupby('labels').count()\n",
    "(count>10).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6683da",
   "metadata": {},
   "source": [
    "#### Aliproducts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e02051b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://tianchi.aliyun.com/competition/entrance/231780/introduction\n",
    "\n",
    "# !wget https://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/231780/AliProducts/100001585554035/train_val.part1.tar.gz -P autodl-tmp/ori_data/Aliproducts/\n",
    "# !wget https://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/231780/AliProducts/200001585540031/train_val.part2.tar.gz -P autodl-tmp/ori_data/Aliproducts/\n",
    "# !wget https://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/231780/AliProducts/300001585559032/train_val.part3.tar.gz -P autodl-tmp/ori_data/Aliproducts/\n",
    "# !wget https://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/231780/AliProducts/400001585578035/train_val.part4.tar.gz -P autodl-tmp/ori_data/Aliproducts/\n",
    "# !wget https://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/231780/AliProducts/500001585599038/train_val.part5.tar.gz -P autodl-tmp/ori_data/Aliproducts/\n",
    "# !wget https://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/231780/AliProducts/600001585536030/train_val.part6.tar.gz -P autodl-tmp/ori_data/Aliproducts/\n",
    "# !wget https://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/231780/AliProducts/700001585524033/train_val.part7.tar.gz -P autodl-tmp/ori_data/Aliproducts/\n",
    "# !wget https://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/231780/AliProducts/800001585502035/train_val.part8.tar.gz -P autodl-tmp/ori_data/Aliproducts/\n",
    "# !wget https://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/231780/AliProducts/900001585552031/train_val.part9.tar.gz -P autodl-tmp/ori_data/Aliproducts/\n",
    "\n",
    "# !mkdir autodl-tmp/ori_data/Aliproducts/train1\n",
    "# !mkdir autodl-tmp/ori_data/Aliproducts/train2\n",
    "# !mkdir autodl-tmp/ori_data/Aliproducts/train3\n",
    "# !mkdir autodl-tmp/ori_data/Aliproducts/train4\n",
    "# !mkdir autodl-tmp/ori_data/Aliproducts/train5\n",
    "# !mkdir autodl-tmp/ori_data/Aliproducts/train6\n",
    "# !mkdir autodl-tmp/ori_data/Aliproducts/train7\n",
    "# !mkdir autodl-tmp/ori_data/Aliproducts/train8\n",
    "# !mkdir autodl-tmp/ori_data/Aliproducts/train9\n",
    "\n",
    "# !tar -zxvf autodl-tmp/ori_data/Aliproducts/train_val.part1.tar.gz -C autodl-tmp/ori_data/Aliproducts/train1\n",
    "# !tar -zxvf autodl-tmp/ori_data/Aliproducts/train_val.part2.tar.gz -C autodl-tmp/ori_data/Aliproducts/train2\n",
    "# !tar -zxvf autodl-tmp/ori_data/Aliproducts/train_val.part3.tar.gz -C autodl-tmp/ori_data/Aliproducts/train3\n",
    "# !tar -zxvf autodl-tmp/ori_data/Aliproducts/train_val.part4.tar.gz -C autodl-tmp/ori_data/Aliproducts/train4\n",
    "# !tar -zxvf autodl-tmp/ori_data/Aliproducts/train_val.part5.tar.gz -C autodl-tmp/ori_data/Aliproducts/train5\n",
    "# !tar -zxvf autodl-tmp/ori_data/Aliproducts/train_val.part6.tar.gz -C autodl-tmp/ori_data/Aliproducts/train6\n",
    "# !tar -zxvf autodl-tmp/ori_data/Aliproducts/train_val.part7.tar.gz -C autodl-tmp/ori_data/Aliproducts/train7\n",
    "# !tar -zxvf autodl-tmp/ori_data/Aliproducts/train_val.part8.tar.gz -C autodl-tmp/ori_data/Aliproducts/train8\n",
    "# !tar -zxvf autodl-tmp/ori_data/Aliproducts/train_val.part9.tar.gz -C autodl-tmp/ori_data/Aliproducts/train9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3ae7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73ef34ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50030/50030 [00:17<00:00, 2935.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_files    148387\n",
      "labels          50030\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_files</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autodl-tmp/ori_data/Aliproducts/train9/val/471...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>autodl-tmp/ori_data/Aliproducts/train9/val/471...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>autodl-tmp/ori_data/Aliproducts/train9/val/447...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>autodl-tmp/ori_data/Aliproducts/train9/val/447...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>autodl-tmp/ori_data/Aliproducts/train9/val/447...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         image_files  labels\n",
       "0  autodl-tmp/ori_data/Aliproducts/train9/val/471...       0\n",
       "1  autodl-tmp/ori_data/Aliproducts/train9/val/471...       0\n",
       "2  autodl-tmp/ori_data/Aliproducts/train9/val/447...       1\n",
       "3  autodl-tmp/ori_data/Aliproducts/train9/val/447...       1\n",
       "4  autodl-tmp/ori_data/Aliproducts/train9/val/447...       1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_classes = glob('autodl-tmp/ori_data/Aliproducts/train9/val/*')\n",
    "full_classes = list(map(lambda x: x.split('/')[-1], full_classes))\n",
    "classes = glob('autodl-tmp/ori_data/Aliproducts/train9/val/*')\n",
    "all_imgs = []\n",
    "all_cls  = []\n",
    "for i in trange(len(classes)):\n",
    "    img_files = glob(os.path.join(classes[i], '*'))\n",
    "    try:\n",
    "        cl = full_classes.index(classes[i].split('/')[-1])\n",
    "    except:\n",
    "        print(classes[i])\n",
    "        full_classes.append(classes[i].split('/')[-1])\n",
    "        cl = full_classes.index(classes[i].split('/')[-1])\n",
    "    all_cls.extend([cl for _ in range(len(img_files))])\n",
    "    all_imgs.extend(img_files)\n",
    "df_dict = {'image_files': all_imgs,\n",
    "           'labels': all_cls}\n",
    "df = pd.DataFrame(df_dict)\n",
    "df.to_csv('autodl-tmp/ori_data/Aliproducts/Aliproducts.csv', index=False)\n",
    "print(df.nunique())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "001e32cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_files    27619\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = df.groupby('labels').count()\n",
    "(count>=3).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d2a907",
   "metadata": {},
   "source": [
    "#### DeepFashion2（hard-triplets）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f91b474d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading deepfashion2-hard-triplets.zip to autodl-tmp/ori_data/DeepFashion2\n",
      "100%|█████████████████████████████████████▉| 7.71G/7.72G [05:56<00:00, 31.1MB/s]\n",
      "100%|██████████████████████████████████████| 7.72G/7.72G [05:56<00:00, 23.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/sangamman/deepfashion2-hard-triplets\n",
    "!kaggle datasets download -d sangamman/deepfashion2-hard-triplets -p autodl-tmp/ori_data/DeepFashion2 --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35bf5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20a75a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33943/33943 [00:09<00:00, 3609.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_files    180024\n",
      "labels          30149\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_files</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autodl-tmp/ori_data/DeepFashion2/fasion_datase...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>autodl-tmp/ori_data/DeepFashion2/fasion_datase...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>autodl-tmp/ori_data/DeepFashion2/fasion_datase...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>autodl-tmp/ori_data/DeepFashion2/fasion_datase...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>autodl-tmp/ori_data/DeepFashion2/fasion_datase...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         image_files  labels\n",
       "0  autodl-tmp/ori_data/DeepFashion2/fasion_datase...       0\n",
       "1  autodl-tmp/ori_data/DeepFashion2/fasion_datase...       0\n",
       "2  autodl-tmp/ori_data/DeepFashion2/fasion_datase...       1\n",
       "3  autodl-tmp/ori_data/DeepFashion2/fasion_datase...       1\n",
       "4  autodl-tmp/ori_data/DeepFashion2/fasion_datase...       2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = glob('autodl-tmp/ori_data/DeepFashion2/*/*/*')\n",
    "full_classes = glob('autodl-tmp/ori_data/DeepFashion2/fasion_dataset_similar_pair_croped_train/*/*')\n",
    "full_classes = list(map(lambda x: x.split('/')[-1], full_classes))\n",
    "all_imgs = []\n",
    "all_cls  = []\n",
    "for i in trange(len(classes)):\n",
    "    img_files = glob(os.path.join(classes[i], '*/*'))\n",
    "    try:\n",
    "        cl = full_classes.index(classes[i].split('/')[-1])\n",
    "    except:\n",
    "        full_classes.append(classes[i].split('/')[-1])\n",
    "        cl = full_classes.index(classes[i].split('/')[-1])\n",
    "    all_cls.extend([cl for _ in range(len(img_files))])\n",
    "    all_imgs.extend(img_files)\n",
    "\n",
    "df_dict = {'image_files': all_imgs,\n",
    "           'labels': all_cls}\n",
    "df = pd.DataFrame(df_dict)\n",
    "df.to_csv('autodl-tmp/ori_data/DeepFashion2/DeepFashion2.csv', index=False)\n",
    "print(df.nunique())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ca4e0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_files    19062\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = df.groupby('labels').count()\n",
    "(count>3).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10303a14",
   "metadata": {},
   "source": [
    "### RP2K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7003325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.pinlandata.com/rp2k_dataset/\n",
    "# !aria2c -x 3 \"https://blob-nips2020-rp2k-dataset.obs.cn-east-3.myhuaweicloud.com/rp2k_dataset.zip\" -d \"autodl-tmp/ori_data/\"\n",
    "# !unzip -q -o autodl-tmp/ori_data/rp2k_dataset -d autodl-tmp/ori_data/rp2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58801faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "485463b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4776/4776 [00:00<00:00, 5309.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_files    384311\n",
      "labels           2388\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_files</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autodl-tmp/ori_data/rp2k/all/train/厨邦美味鲜/0514_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>autodl-tmp/ori_data/rp2k/all/train/厨邦美味鲜/0514_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>autodl-tmp/ori_data/rp2k/all/train/厨邦美味鲜/0514_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>autodl-tmp/ori_data/rp2k/all/train/厨邦美味鲜/0430_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>autodl-tmp/ori_data/rp2k/all/train/厨邦美味鲜/0514_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         image_files  labels\n",
       "0  autodl-tmp/ori_data/rp2k/all/train/厨邦美味鲜/0514_...       0\n",
       "1  autodl-tmp/ori_data/rp2k/all/train/厨邦美味鲜/0514_...       0\n",
       "2  autodl-tmp/ori_data/rp2k/all/train/厨邦美味鲜/0514_...       0\n",
       "3  autodl-tmp/ori_data/rp2k/all/train/厨邦美味鲜/0430_...       0\n",
       "4  autodl-tmp/ori_data/rp2k/all/train/厨邦美味鲜/0514_...       0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_classes = glob('autodl-tmp/ori_data/rp2k/all/train/*')\n",
    "full_classes = list(map(lambda x: x.split('/')[-1], full_classes))\n",
    "classes = glob('autodl-tmp/ori_data/rp2k/all/*/*')\n",
    "all_imgs = []\n",
    "all_cls  = []\n",
    "for i in trange(len(classes)):\n",
    "    img_files = glob(os.path.join(classes[i], '*'))\n",
    "    try:\n",
    "        cl = full_classes.index(classes[i].split('/')[-1])\n",
    "    except:\n",
    "        print(classes[i])\n",
    "        full_classes.append(classes[i].split('/')[-1])\n",
    "        cl = full_classes.index(classes[i].split('/')[-1])\n",
    "    all_cls.extend([cl for _ in range(len(img_files))])\n",
    "    all_imgs.extend(img_files)\n",
    "df_dict = {'image_files': all_imgs,\n",
    "           'labels': all_cls}\n",
    "df = pd.DataFrame(df_dict)\n",
    "df.to_csv('autodl-tmp/ori_data/rp2k/rp2k.csv', index=False)\n",
    "print(df.nunique())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27035206",
   "metadata": {},
   "source": [
    "### Shopee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0798b725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading shopee-product-matching.zip to autodl-tmp/ori_data/Shopee\n",
      "100%|█████████████████████████████████████▊| 1.68G/1.68G [01:16<00:00, 25.9MB/s]\n",
      "100%|██████████████████████████████████████| 1.68G/1.68G [01:16<00:00, 23.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/competitions/shopee-product-matching\n",
    "\n",
    "# !kaggle competitions download -c shopee-product-matching -p autodl-tmp/ori_data/Shopee\n",
    "# !unzip -q -o autodl-tmp/ori_data/Shopee/shopee-product-matching.zip -d autodl-tmp/ori_data/Shopee/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28338d6a",
   "metadata": {},
   "source": [
    "### JD-product-10K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e14b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/products-10k\n",
    "# !aria2c -x 4 \"https://hxppaq.bl.files.1drv.com/y4mM4VFu53lo1i8OW7HhQlmP5YJANItp3B0Wc8UAD4V84pPmy5arhJdpxpvS-mpk_6Rv9POdJnpqpNnOqJ39DR3FfG5rhMisAztLk-wi7ZCQ0F63N1gZRVkz6NQMZLNamTfo818P6tWficovSKTFASeWmdh_q-lp6Pkly6kPo5KREvqwXaFKZAb40duubnevFntFeIqNx78HhwwDJVWgS-r-A\" -d \"autodl-tmp/ori_data/\"\n",
    "# !aria2c -x 4 \"https://hxppaq.bl.files.1drv.com/y4mRRNNq8uUa-jR4FBBllPtxas1R00_ytt5IIXPFIWVZfxbBndfVZRRUebeWs9nWE3aowktixlQsXNZhFes-Cr_P26suWxEAA72YK1AsvNMSbqpxunzqxtGoPOanyS6xVM3lRDg0kol8HljzHnQ3rgJTmwb4qEX5g_TBoCvgE2bX7RdX-zWt1JnIDeqQrJDiMEayBMagPrKI7ld-flEqenCIg\" -d \"autodl-tmp/ori_data/\"\n",
    "# !unzip -q -o autodl-tmp/ori_data/products10k_test.zip -d autodl-tmp/ori_data/JD_Products_10K\n",
    "# !unzip -q -o autodl-tmp/ori_data/products10k_train.zip -d autodl-tmp/ori_data/JD_Products_10K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65032e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
