{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73625e66-d7eb-413f-b9a2-8d016725c34f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Shopee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac4251f-16fd-4fbb-bb5a-3c83ac2f0977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cf4bcf-7467-4536-8f33-4e6d4516af68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('final_data_224/Shopee/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95afd84f-903f-4355-8214-565fe1d22b81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Shopee/train.csv')\n",
    "df.drop_duplicates(subset='image', inplace=True)\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('label_group')):\n",
    "    if len(group)<3:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    all_groups.append(group)\n",
    "    for idx, row in group.iterrows():\n",
    "        file = row['image']\n",
    "        path = 'Shopee/train_images/'+file\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = 'final_data_224/Shopee/images/'+file\n",
    "        cv2.imwrite(new_path, img)\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('final_data_224/Shopee/Shopee_final_224.csv', index=False)\n",
    "\n",
    "all_files = glob('final_data_224/Shopee/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0], (len(all_files), df_n100_224.shape[0])\n",
    "print(df.shape[0], df['label_group'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['label_group'].nunique())\n",
    "df_n100_224.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852a8fb9-0ed9-42c6-82f6-b792da59c7b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### JD-product-10K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794d4f82-4954-4cc1-81eb-8e925b767da7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('final_data_224/Products10K/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4426bcb-f39a-4561-9f22-b50282a49098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('products10k/train.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('class')):\n",
    "    if len(group)<5:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    all_groups.append(group)\n",
    "    for idx, row in group.iterrows():\n",
    "        file = row['name']\n",
    "        path = 'products10k/train/'+file\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = 'final_data_224/Products10K/images/'+f'{file}'\n",
    "        cv2.imwrite(new_path, img)\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('final_data_224/Products10K/products10K_final_224.csv', index=False)\n",
    "all_files = glob('final_data_224/Products10K/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0]\n",
    "print(df.shape[0], df['class'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['class'].nunique())\n",
    "df_n100_224.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f12af9a-4188-4f9a-8a6b-c68b78ea245a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Stanford_Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928fbf0-bbb4-4008-88ad-831d20aa4245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('final_data_224/Stanford_Products/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a90f656-2bd7-47e9-8310-44ab57a1eef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Stanford_Online_Products/Stanford_Products_extracted.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('labels')):\n",
    "    if len(group)<5:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    for idx, row in group.iterrows():\n",
    "        path = row['image_files']\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = 'final_data_224/Stanford_Products/images/'+path.split('/')[-2]+path.split('/')[-1]\n",
    "        cv2.imwrite(new_path, img)\n",
    "        group.loc[idx, 'image_files'] = new_path\n",
    "    all_groups.append(group)\n",
    "    \n",
    "\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('final_data_224/Stanford_Products/Stanford_Products_final_224.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d176514-7e02-4632-9439-47e8de92df34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_files = glob('final_data_224/Stanford_Products/images/*')\n",
    "print(len(all_files))\n",
    "assert len(all_files)==df_n100_224.shape[0]\n",
    "print(df.shape[0], df['labels'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['labels'].nunique())\n",
    "df_n100_224.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe85fa0-9e12-42ee-a124-7d4981aea5ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Deep Fashion （Consumer-to-shop）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e8bfa1-d406-4121-b79d-057a236d5d65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('final_data_224/deepFashion/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3130471b-ed9a-4189-9324-2666e4a37337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('deepFashion/deepFashion_extracted.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('labels')):\n",
    "    if len(group)<3:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    for idx, row in group.iterrows():\n",
    "        path = row['image_files']\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = 'final_data_224/deepFashion/images/'+f'f_{label}_{idx}_'+path.split('/')[-1]\n",
    "        cv2.imwrite(new_path, img)\n",
    "        group.loc[idx, 'image_files'] = new_path\n",
    "    all_groups.append(group)\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('final_data_224/deepFashion/DeepFashion_final_224.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e803b805-eef9-4dc0-a09f-95a2e756b3ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_files = glob('final_data_224/deepFashion/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0],(len(all_files), df_n100_224.shape[0])\n",
    "print(df.shape[0], df['labels'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['labels'].nunique())\n",
    "df_n100_224.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b0456d-18f5-4c41-bb19-c4c45e5e1894",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Grocery Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bb913b-0d57-4bbf-a8c3-36080fd1326a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('final_data_224/grocery_dataset/images', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea9bdf3-d82c-46fa-91f6-e84a88f00350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('GroceryStoreDataset/grocery_dataset_extracted.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('labels')):\n",
    "    if len(group)<5:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    del_idx=[]\n",
    "    for idx, row in group.iterrows():\n",
    "        path = row['image_files']\n",
    "        img = cv2.imread(path)\n",
    "        if img is not None:\n",
    "            min_ = min(img.shape[:2])\n",
    "            max_ = max(img.shape[:2])\n",
    "            if min_>224:\n",
    "                img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "            elif max_>224:\n",
    "                img = cv2.resize(img, (224, 224))\n",
    "            new_path = 'final_data_224/grocery_dataset/images/'+path.split('/')[-4]+path.split('/')[-1]\n",
    "            cv2.imwrite(new_path, img)\n",
    "            group.loc[idx, 'image_files'] = new_path\n",
    "        else:\n",
    "            del_idx.append(idx)\n",
    "    # print(del_idx)\n",
    "    if(len(del_idx)>0):\n",
    "        group = group.drop(index=del_idx)\n",
    "    all_groups.append(group)\n",
    "    \n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('final_data_224/grocery_dataset/grocery_dataset_final_224.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1dba9-e215-40f0-84b9-6b1c375ed7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_files = glob('final_data_224/grocery_dataset/images/*')\n",
    "print(len(all_files), df_n100_224.shape[0])\n",
    "print(df_n100_224.iloc[6])\n",
    "assert len(all_files)==df_n100_224.shape[0]\n",
    "print(df.shape[0], df['labels'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['labels'].nunique())\n",
    "df_n100_224.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146ed61-d5e7-4543-818b-2b3bed41ec4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Fashion200K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62728504-271e-478a-9ef2-abee5b49a7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('final_data_224/Fashion_200K/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab6cd92-b34e-449d-ad71-d3a64ced4823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Fashion_200K/Fashion_200K_extracted.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('labels')):\n",
    "    if len(group)<3:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    for idx, row in group.iterrows():\n",
    "        path = row['image_files']\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = 'final_data_224/Fashion_200K/images/'+path.split('/')[-3]+path.split('/')[-1]\n",
    "        cv2.imwrite(new_path, img)\n",
    "        group.loc[idx, 'image_files'] = new_path\n",
    "    all_groups.append(group)\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('final_data_224/Fashion_200K/Fashion_200K_final_224.csv', index=False)\n",
    "\n",
    "all_files = glob('final_data_224/Fashion_200K/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0], (len(all_files), df_n100_224.shape[0])\n",
    "print(df.shape[0], df['labels'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['labels'].nunique())\n",
    "df_n100_224.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d15f7-deb9-4c25-86c4-bccb363fc63e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### RP2K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7156b4ce-d02e-41b5-b24a-acd68398df7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('final_data_224/rp2k/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e67ea-cb13-4113-8cec-702cd1f66f28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('rp2k/rp2k_extracted.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('labels')):\n",
    "    if len(group)<5:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    del_idx = []\n",
    "    for idx, row in group.iterrows():\n",
    "        path = row['image_files']\n",
    "        img = cv2.imread(path)\n",
    "        if img is not None:\n",
    "            min_ = min(img.shape[:2])\n",
    "            max_ = max(img.shape[:2])\n",
    "            if min_>224:\n",
    "                img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "            elif max_>224:\n",
    "                img = cv2.resize(img, (224, 224))\n",
    "            new_path = 'final_data_224/rp2k/images/'+path.split('/')[-1]\n",
    "            if not cv2.imwrite(new_path, img):\n",
    "                raise Exception(\"Could not write image\")\n",
    "            group.loc[idx, 'image_files'] = new_path\n",
    "        else:\n",
    "            del_idx.append(idx)\n",
    "    if(len(del_idx)>0):\n",
    "        group = group.drop(index=del_idx)\n",
    "    all_groups.append(group)\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('final_data_224/rp2k/rp2k_final_224.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a646a46e-a171-47a8-b887-c467a115231b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_files = glob('final_data_224/rp2k/images/*')\n",
    "# assert len(all_files)==df_n100_224.shape[0], (len(all_files), df_n100_224.shape[0])\n",
    "#assert fails but images are present\n",
    "print(df.shape[0], df['labels'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['labels'].nunique())\n",
    "df_n100_224.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471e4a3c-e456-41f3-a8c1-d8beeeaf4551",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### DeepFashion2 （hard-triplets）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5af7aad-dbbf-4191-acf4-1bc258fbe4c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "os.makedirs('final_data_224/DeepFashion2/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c801c7-64b9-4656-b579-988f9998f2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('deepFashion2/deepFashion2_extracted.csv')\n",
    "all_groups = []\n",
    "n = 0\n",
    "for label, group in tqdm(df.groupby('labels')):\n",
    "    if len(group)<3:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    \n",
    "    for idx, row in group.iterrows():\n",
    "        path = row['image_files']\n",
    "        img = cv2.imread(path)\n",
    "        if img is not None:\n",
    "            min_ = min(img.shape[:2])\n",
    "            max_ = max(img.shape[:2])\n",
    "            if min_>224:\n",
    "                img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "            elif max_>224:\n",
    "                img = cv2.resize(img, (224, 224))\n",
    "            new_path = f'final_data_224/DeepFashion2/images/{n}_'+path.split('/')[-1]\n",
    "            cv2.imwrite(new_path, img)\n",
    "            group.loc[idx, 'image_files'] = new_path\n",
    "            n+=1\n",
    "    all_groups.append(group)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da004da5-759b-43d6-9a12-bff0710a57f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb41dac-09da-4f59-93bb-6f9e77e3c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('final_data_224/DeepFashion2/DeepFashion2_final_224.csv', index=False)\n",
    "\n",
    "all_files = glob('final_data_224/DeepFashion2/images/*')\n",
    "# assert len(all_files)==df_n100_224.shape[0], (len(all_files), df_n100_224.shape[0])\n",
    "print(df.shape[0], df['labels'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['labels'].nunique(), df_n100_224['image_files'].nunique())\n",
    "df_n100_224.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de3fc3-ead0-433c-be08-fb55743cd631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2ca64-4bfa-4704-8f58-5df5b60613d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
